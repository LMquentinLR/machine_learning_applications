{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of CNNs on MNIST dataset with Tensorflow 2.x.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><b>Warning:</b></u> This notebook runs on tensorflow version 1.14 (tested using an installation of tensorflow-gpu v1.14.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing datasets\n",
    "The MNIST datasets are kindly provided by Yann Lecun on his [website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "They are directly accessibly through the tensorflow library as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image n째37562's label is 4.\n",
      "The image is of shape (28, 28).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANs0lEQVR4nO3df6zV9X3H8dcLCtcGqRUY9A7pDyk2ozWT5hZrbIwbmVGzDG3SpSwxzDFvs5TFJv1jxiWr/zR1S2tjOmtGBxPXjsbMEqk1bRkzo10NcrVMscxhHbUUClXGoDW9/Ljv/XG/LFe853Mu53zPD3g/H8nNOef7Pud833z1db7fez7f7/04IgTgwjet1w0A6A7CDiRB2IEkCDuQBGEHknhLN1c20wNxkWZ1c5VAKr/Wr3QiRj1Zra2w275R0v2Spkv6+4i4t/T8izRLV3tFO6sEULAjtjWstXwYb3u6pAck3SRpqaRVtpe2+n4AOqud39mXS3opIl6OiBOSvi5pZT1tAahbO2FfKOmnEx7vr5a9ge1h2yO2R05qtI3VAWhHO2Gf7EuAN517GxHrImIoIoZmaKCN1QFoRzth3y9p0YTHl0k60F47ADqlnbDvlLTE9ntsz5T0cUlb6mkLQN1aHnqLiFO210r6jsaH3jZExAu1dQagVm2Ns0fEE5KeqKkXAB3E6bJAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJNqastn2PknHJZ2WdCoihupoCkD92gp75Xci4tUa3gdAB3EYDyTRbthD0ndtP2N7eLIn2B62PWJ75KRG21wdgFa1exh/bUQcsD1f0lbb/xkR2yc+ISLWSVonSW/znGhzfQBa1NaePSIOVLeHJW2WtLyOpgDUr+Ww255le/aZ+5JukLS7rsYA1Kudw/gFkjbbPvM+/xQR366lK7zB9KVXFOt/9fimhrW1n11bfO3c9U+11FM3tPPvlqQ//bs/b1hb+Nc/aKmn81nLYY+IlyX9do29AOgght6AJAg7kARhB5Ig7EAShB1Ioo4LYdBho++YXawvGxhr/Nrf/9/ym69vpaPuOHbfqWK99O/Gm7FnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGc/D7y+YEaxPq3wmf2bn5tedztd829X/nOxvnO0vK/KeBlrCXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfbzwNH3lT+Tx3RhXtc9pvIEQrdvbPynoiXpnWKcfSL27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPs54G5H/55sV66nv21Ky8uv/fTLbVUi9fWXFOsT9Ozxfro3NN1tnPBa7pnt73B9mHbuycsm2N7q+291e2lnW0TQLumchj/kKQbz1p2l6RtEbFE0rbqMYA+1jTsEbFd0pGzFq+UtLG6v1HSLTX3BaBmrX5BtyAiDkpSdTu/0RNtD9sesT1yUqMtrg5Auzr+bXxErIuIoYgYmqGBTq8OQAOthv2Q7UFJqm4P19cSgE5oNexbJK2u7q+W9Fg97QDolKbj7LY3Sbpe0jzb+yV9RtK9kh6xvUbSK5I+1skmL3jLryyWn7zyoWL9gaOLG9bmrn+qlY664oa1/16sN7ue/fLNJ+ts54LXNOwRsapBaUXNvQDoIE6XBZIg7EAShB1IgrADSRB2IAkuce2C6W+/pFi/6R+2F+vT5GL98bW/23jdTS4T7bTpS69oWPuDSzYVX/ut18vbbWDvoWL9VLGaD3t2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYuGP3ge4v14bf/S7G+c7T8mTzz58cb1nr9x5YPrJjXsLZsoDzV9Ae+eluxfvn+/r18tx+xZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn74L/vrW8mUtTLkvSqn/9RLF+xezG02rt/dLVxde++NEvF+s/PFEeC1+98c5iffcdf9uwNtbk3z1wpHwdP84Ne3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9hq8tuaaYv3FjzYea5akMZXHsj9/3SPF+oduONCwNjj9rW2te9nM8v5g1x33N3n/xq9vtu65P+Ivv9ep6Z7d9gbbh23vnrDsHts/s72r+rm5s20CaNdUDuMfknTjJMu/GBFXVT9P1NsWgLo1DXtEbJd0pAu9AOigdr6gW2v7ueow/9JGT7I9bHvE9shJNT6HG0BntRr2ByUtlnSVpIOSvtDoiRGxLiKGImJohgZaXB2AdrUU9og4FBGnI2JM0lckLa+3LQB1aynstgcnPLxV0u5GzwXQH5qOs9veJOl6SfNs75f0GUnX275KUkjaJ6l8wfUF7tfzytddN5tfvdln7i2zjhbrXz76/oa1x2+/rrzqp58vlt+y6LJi/U+2leeWL/X+vkfXFl+75Js7inWcm6Zhj4hVkyxe34FeAHQQp8sCSRB2IAnCDiRB2IEkCDuQBJe4dsGYolh/4OjiYn3jg+WLCgcfLpzmcKw8tNbMqcGGZ0JLkj50UePLayVpTI0vsb1888mWekJr2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs9dg4ZPHi/VrXi1fyjl3/VPF+nz9oFg/Xay259TFM4v1Zn+q+luvX9KwNrD3UHndxSrOFXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfY6NPlzzHOf7lIfHfDa+8uz+DSbdvmzn7utYW3O/vL5BagXe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9uSaTcl8x599s1if1mR/MWcDY+n9oume3fYi20/a3mP7Bdt3Vsvn2N5qe291W55NAEBPTeUw/pSkT0fEb0n6sKRP2l4q6S5J2yJiiaRt1WMAfapp2CPiYEQ8W90/LmmPpIWSVkraWD1to6RbOtUkgPad0xd0tt8taZmkHZIWRMRBafwDQdL8Bq8Ztj1ie+SkRtvrFkDLphx22xdLelTSpyLi2FRfFxHrImIoIoZmqHxRBYDOmVLYbc/QeNC/FhHfqBYfsj1Y1QclHe5MiwDq0HTozbYlrZe0JyLum1DaImm1pHur28c60iE66id/9M5iffiS8n/WZpe4on9MZZz9Wkm3SXre9q5q2d0aD/kjttdIekXSxzrTIoA6NA17RHxfkhuUV9TbDoBO4XRZIAnCDiRB2IEkCDuQBGEHkuAS1+wajbNUZnh6sX77K9c3WUF5Omt0D3t2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfbsolw+GaeL9e/9+L3F+mL98Fw7QoewZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnT+5XS04U682uZ5/91FvrbAcdxJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5KYyvzsiyQ9LOkdksYkrYuI+23fI+kOSb+onnp3RDzRqUbRGbP2zizWv/Q/7yrWBx/eXayXr4ZHN03lpJpTkj4dEc/ani3pGdtbq9oXI+LznWsPQF2mMj/7QUkHq/vHbe+RtLDTjQGo1zn9zm773ZKWSdpRLVpr+znbG2xf2uA1w7ZHbI+c1GhbzQJo3ZTDbvtiSY9K+lREHJP0oKTFkq7S+J7/C5O9LiLWRcRQRAzN0EANLQNoxZTCbnuGxoP+tYj4hiRFxKGIOB0RY5K+Iml559oE0K6mYbdtSesl7YmI+yYsH5zwtFsllb+WBdBTjij/LWHbH5H0PUnPa3zoTZLulrRK44fwIWmfpE9UX+Y19DbPiau9os2WATSyI7bpWByZdCLuqXwb/31NPos3Y+rAeYQz6IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0k0vZ691pXZv5D0kwmL5kl6tWsNnJt+7a1f+5LorVV19vauiPiNyQpdDfubVm6PRMRQzxoo6Nfe+rUvid5a1a3eOIwHkiDsQBK9Dvu6Hq+/pF9769e+JHprVVd66+nv7AC6p9d7dgBdQtiBJHoSdts32n7R9ku27+pFD43Y3mf7edu7bI/0uJcNtg/b3j1h2RzbW23vrW4nnWOvR73dY/tn1bbbZfvmHvW2yPaTtvfYfsH2ndXynm67Ql9d2W5d/53d9nRJ/yXp9yTtl7RT0qqI+FFXG2nA9j5JQxHR8xMwbF8n6ZeSHo6ID1TL/kbSkYi4t/qgvDQi/qJPertH0i97PY13NVvR4MRpxiXdIumP1cNtV+jrD9WF7daLPftySS9FxMsRcULS1yWt7EEffS8itks6ctbilZI2Vvc3avx/lq5r0FtfiIiDEfFsdf+4pDPTjPd02xX66opehH2hpJ9OeLxf/TXfe0j6ru1nbA/3uplJLDgzzVZ1O7/H/Zyt6TTe3XTWNON9s+1amf68Xb0I+2RTSfXT+N+1EfFBSTdJ+mR1uIqpmdI03t0yyTTjfaHV6c/b1Yuw75e0aMLjyyQd6EEfk4qIA9XtYUmb1X9TUR86M4NudXu4x/38v36axnuyacbVB9uul9Of9yLsOyUtsf0e2zMlfVzSlh708Sa2Z1VfnMj2LEk3qP+mot4iaXV1f7Wkx3rYyxv0yzTejaYZV4+3Xc+nP4+Irv9Iulnj38j/WNJf9qKHBn1dLuk/qp8Xet2bpE0aP6w7qfEjojWS5kraJmlvdTunj3r7R41P7f2cxoM12KPePqLxXw2fk7Sr+rm519uu0FdXthunywJJcAYdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTxf9pEA2PpKlOtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing random image and its label from the training set.\n",
    "random_image = rd.randrange(train_images.shape[0])\n",
    "plt.imshow(train_images[random_image])\n",
    "print(f\"Image n째{random_image}'s label is {train_labels[random_image]}.\")\n",
    "print(f\"The image is of shape {train_images[random_image].shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "<u>1. Declaring pre-processing functions:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(array):\n",
    "    \"\"\"\n",
    "    Converts a numpy array of shape (number_instances, 1) to one-hot encodings\n",
    "    of shape (number_instances, number_labels)\n",
    "    ---\n",
    "    variable <array>: <class 'numpy.ndarray'>\n",
    "    \"\"\"\n",
    "    # Using np.reshape is necessary so the one-hot encodings are not a nested list.\n",
    "    new_array = np.array(array).reshape(-1)\n",
    "    return np.eye(np.max(array)+1)[new_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Reshaping train and test image/label arrays:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:\n",
      "- Training features array: (60000, 28, 28)\n",
      "- Training labels array: (60000, 1)\n",
      "- Testing features array: (10000, 28, 28)\n",
      "- Testing labels array: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping labels to indicate the dimension of the secondary axis\n",
    "train_labels = np.reshape(train_labels,(train_labels.shape[0],1))\n",
    "test_labels = np.reshape(test_labels,(test_labels.shape[0],1))\n",
    "\n",
    "print(\"Dimensions of:\",\n",
    "      \"- Training features array: \" + str(train_images.shape),\n",
    "      \"- Training labels array: \" + str(train_labels.shape),\n",
    "      \"- Testing features array: \" + str(test_images.shape),\n",
    "      \"- Testing labels array: \" + str(test_labels.shape),\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>3. Normalizing features:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing features.\n",
    "norm_train_images = train_images.astype(np.float32)/np.max(train_images) #i.e. /255\n",
    "norm_test_images = test_images/np.max(test_images) #i.e. /255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>4. Converting train and test labels arrays to one-hot encodings:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_labels = convert_to_one_hot(train_labels)\n",
    "encoded_test_labels = convert_to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:\n",
      "- Training labels one-hot encoded array:(60000, 10)\n",
      "- Test labels one-hot encoded array:(10000, 10)\n",
      "\n",
      "Image n째37562's one-hot encoding is [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.].\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of:\",\n",
    "      \"- Training labels one-hot encoded array:\" + str(encoded_train_labels.shape),\n",
    "      \"- Test labels one-hot encoded array:\" + str(encoded_test_labels.shape),\n",
    "      \"\\nImage n째\" + str(random_image) + \"'s one-hot encoding is \" + \\\n",
    "      str(encoded_train_labels[random_image]) + \".\",\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Laying out the CNN Model\n",
    "\n",
    "<u>1. Declaring pre-processing functions:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Setting up parameters and hyperparameters:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>3. Setting up tensorflow session structure:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
