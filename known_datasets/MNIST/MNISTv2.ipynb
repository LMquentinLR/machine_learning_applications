{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of CNNs on MNIST dataset with Tensorflow 2.x.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow Version: 7.2.0\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "print('Pillow Version:', PIL.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><b>Warning:</b></u> This notebook runs on tensorflow version 1.14 (tested using an installation of tensorflow-gpu v1.14.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing datasets\n",
    "The MNIST datasets are kindly provided by Yann Lecun on his [website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "They are directly accessibly through the tensorflow library as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>1. Building the training pipeline.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"\n",
    "  Normalizes images: `uint8` -> `float32`.\n",
    "  \"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Building the testing pipeline.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Laying out  and training the model\n",
    "\n",
    "<u>1. Declaring the model.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Compiling the model.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>3. Fitting the model.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.3625 - accuracy: 0.8997 - val_loss: 0.1985 - val_accuracy: 0.9421\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1639 - accuracy: 0.9539 - val_loss: 0.1430 - val_accuracy: 0.9590\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1191 - accuracy: 0.9658 - val_loss: 0.1076 - val_accuracy: 0.9685\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0928 - accuracy: 0.9731 - val_loss: 0.0983 - val_accuracy: 0.9692\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0751 - accuracy: 0.9780 - val_loss: 0.0860 - val_accuracy: 0.9747\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.0840 - val_accuracy: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4cced22b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array(Image.open('test_image.png').convert('L'))\n",
    "\n",
    "pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(image).reshape(-1, image.shape[0], image.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
