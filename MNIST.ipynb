{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP - Application of CNNs on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random as rd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing datasets\n",
    "The MNIST datasets are kindly provided by Yann Lecun on his [website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "They are directly accessibly through the tensorflow library as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image n째15209's label is 7.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing random image and its label from the training set.\n",
    "random_image = rd.randrange(train_images.shape[0])\n",
    "plt.imshow(train_images[random_image])\n",
    "print(\"\\nImage n째\" + str(random_image) + \"'s label is \" + str(train_labels[random_image]) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "<u>1. Declaring pre-processing functions:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(array):\n",
    "    \"\"\"\n",
    "    Converts a numpy array of shape (number_instances, 1) to one-hot encodings\n",
    "    of shape (number_instances, number_labels)\n",
    "    ---\n",
    "    variable <array>: <class 'numpy.ndarray'>\n",
    "    \"\"\"    \n",
    "    # Using np.reshape is necessary so the one-hot encodings are not a nested list.\n",
    "    new_array = np.array(array).reshape(-1)\n",
    "    return np.eye(np.max(array)+1)[new_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Reshaping train and test image/label arrays:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:\n",
      "- Training features array: (60000, 28, 28, 1)\n",
      "- Training labels array: (60000, 1)\n",
      "- Testing features array: (10000, 28, 28, 1)\n",
      "- Testing features array: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Expanding by 1 the dimension of train and test images to indicate that MNIST data are \n",
    "#in greyscale, i.e. 1 channel\n",
    "train_images = np.expand_dims(train_images,axis=3)\n",
    "test_images = np.expand_dims(test_images,axis=3)\n",
    "\n",
    "# Reshaping labels to indicate the dimension of the secondary axis\n",
    "train_labels = np.reshape(train_labels,(train_labels.shape[0],1))\n",
    "test_labels = np.reshape(test_labels,(test_labels.shape[0],1))\n",
    "\n",
    "print(\"Dimensions of:\",\n",
    "      \"- Training features array: \" + str(train_images.shape), \n",
    "      \"- Training labels array: \" + str(train_labels.shape), \n",
    "      \"- Testing features array: \" + str(test_images.shape), \n",
    "      \"- Testing features array: \" + str(test_labels.shape), \n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>3. Normalizing features:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing features. \n",
    "norm_train_images = train_images.astype(np.float32)/np.max(train_images) #i.e. /255\n",
    "norm_test_images = test_images/np.max(test_images) #i.e. /255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>4. Converting train and test labels arrays to one-hot encodings:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_labels = convert_to_one_hot(train_labels)\n",
    "encoded_test_labels = convert_to_one_hot(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:\n",
      "- Training labels one-hot encoded array:(60000, 10)\n",
      "- Test labels one-hot encoded array:(60000, 10)\n",
      "\n",
      "Image n째15209's one-hot encoding is [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.].\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of:\",\n",
    "      \"- Training labels one-hot encoded array:\" + str(encoded_train_labels.shape),\n",
    "      \"- Test labels one-hot encoded array:\" + str(encoded_test_labels.shape),\n",
    "      \"\\nImage n째\" + str(random_image) + \"'s one-hot encoding is \" + \\\n",
    "      str(encoded_train_labels[random_image]) + \".\",\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Laying out the CNN Model\n",
    "\n",
    "<u>1. Declaring pre-processing functions:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_shape(array):\n",
    "    \"\"\"\n",
    "    Returns the height, width of instance data.\n",
    "    ---\n",
    "    variable <array>: <class 'numpy.ndarray'>\n",
    "    \"\"\"\n",
    "    return array.shape[1], array.shape[2]\n",
    "    \n",
    "def tensorflow_placeholders(instance_height, \n",
    "                            instance_width, \n",
    "                            instance_channels, \n",
    "                            label_numbers):\n",
    "    \"\"\"\n",
    "    Creates tensorflow placeholders for a tensorflow session.\n",
    "    ---\n",
    "    variables: <class 'int'>\n",
    "    <instance_height>, <instance_width>, <instance_channel>, <label_numbers>\n",
    "    \"\"\"\n",
    "    placeholder_data = tf.placeholder(tf.float32, shape=(None, \n",
    "                                                         instance_height,\n",
    "                                                         instance_width,\n",
    "                                                         instance_channels))\n",
    "    placeholder_labels = tf.placeholder(tf.float32, shape=(None, label_numbers))\n",
    "    return placeholder_data, placeholder_labels\n",
    "\n",
    "def initialize_parameters(filter_shape):\n",
    "    \"\"\"\n",
    "    Initializes weght parameters and returns returns a tensor with shape:\n",
    "    [filter_height, filter_width, in_channels, out_channels].\n",
    "    ---\n",
    "    variable: <class 'lst'>\n",
    "    <filter_shape> listing variables: <class 'int'>\n",
    "    <filter_height>, <filter_width>, <channels_in>, <channels_out>\n",
    "    \"\"\"\n",
    "    weights = tf.get_variable(\"W\", filter_shape, \n",
    "                              initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Setting up tensorflow session:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeds random numbers for tensor parameters\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# Scalar used for setting up tensorflow session.\n",
    "instance_height, instance_width = instance_shape(norm_train_images)\n",
    "instance_channels = 1\n",
    "label_numbers = encoded_train_labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow placeholder for instance data:\n",
      "Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensorflow placeholder for instance labels:\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creating tensorflow placeholders.\n",
    "placeholder_data, placeholder_labels = tensorflow_placeholders(instance_height, \n",
    "                                                               instance_width, \n",
    "                                                               instance_channels, \n",
    "                                                               label_numbers)\n",
    "print(\"Tensorflow placeholder for instance data:\",\n",
    "      placeholder_data,\n",
    "      \"Tensorflow placeholder for instance labels:\",\n",
    "      placeholder_labels\n",
    "      , sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the wights parameters\n",
    "convolution_filter_shapes = {[1,1,1,16],\n",
    "                             [4,4,16,16],\n",
    "                             [2,2,16,8],\n",
    "                             [2,2,8,8]}\n",
    "parameters = {\"W1\":initialize_parameters(convolution_filter_shapes[0]),\n",
    "              \"W2\":initialize_parameters(convolution_filter_shapes[1]),\n",
    "              \"W3\":initialize_parameters(convolution_filter_shapes[2]),\n",
    "              \"W4\":initialize_parameters(convolution_filter_shapes[3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"WIP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"WIP\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
