{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP - Application of CNNs on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random as rd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing datasets\n",
    "The MNIST datasets are kindly provided by Yann Lecun on his [website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "They are directly accessibly through the tensorflow library as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image n째53614's label is 7.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing random image and its label from the training set\n",
    "random_image = rd.randrange(train_images.shape[0])\n",
    "plt.imshow(train_images[random_image])\n",
    "print(\"\\nImage n째\" + str(random_image) + \"'s label is \" + str(train_labels[random_image]) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "<u>1. Declaring pre-processing functions:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(array):\n",
    "    \"\"\"\n",
    "    Converts a numpy array of shape (number_instances, 1) to one-hot encodings\n",
    "    of shape (number_instances, number_labels)\n",
    "    \"\"\"    \n",
    "    # Using np.reshape is necessary so the one-hot encodings are not a nested list\n",
    "    new_array = np.array(array).reshape(-1)\n",
    "    return np.eye(np.max(array)+1)[new_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Reshaping train and test label arrays:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:\n",
      "- Training features array: (60000, 28, 28)\n",
      "- Training labels array: (60000, 1)\n",
      "- Testing features array: (10000, 28, 28)\n",
      "- Testing features array: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_labels = np.reshape(train_labels,(train_labels.shape[0],1))\n",
    "test_labels = np.reshape(test_labels,(test_labels.shape[0],1))\n",
    "print(\"Dimensions of:\",\n",
    "      \"- Training features array: \" + str(train_images.shape), \n",
    "      \"- Training labels array: \" + str(train_labels.shape), \n",
    "      \"- Testing features array: \" + str(test_images.shape), \n",
    "      \"- Testing features array: \" + str(test_labels.shape), \n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>3. Normalizing features:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing features\n",
    "norm_train_images = train_images/np.max(train_images) #i.e. /255\n",
    "norm_test_images = test_images/np.max(test_images) #i.e. /255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>4. Converting train and test labels arrays to one-hot encodings:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_labels = convert_to_one_hot(train_labels)\n",
    "encoded_test_labels = convert_to_one_hot(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:\n",
      "- Training labels one-hot encoded array:(60000, 10)\n",
      "- Test labels one-hot encoded array:(60000, 10)\n",
      "\n",
      "Image n째53614's one-hot encoding is [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.].\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of:\",\n",
    "      \"- Training labels one-hot encoded array:\" + str(encoded_train_labels.shape),\n",
    "      \"- Test labels one-hot encoded array:\" + str(encoded_test_labels.shape),\n",
    "      \"\\nImage n째\" + str(random_image) + \"'s one-hot encoding is \" + \\\n",
    "      str(encoded_train_labels[random_image]) + \".\",\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Laying out the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"WIP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"WIP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"WIP\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
