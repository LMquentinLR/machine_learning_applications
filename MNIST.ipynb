{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP - Application of CNNs on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><b>Warning:</b></u> This notebook runs on tensorflow version 1.14 (tested using an installation of tensorflow-gpu v1.14.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing datasets\n",
    "The MNIST datasets are kindly provided by Yann Lecun on his [website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "They are directly accessibly through the tensorflow library as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image n째49456's label is 6.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing random image and its label from the training set.\n",
    "random_image = rd.randrange(train_images.shape[0])\n",
    "plt.imshow(train_images[random_image])\n",
    "print(\"\\nImage n째\" + str(random_image) + \"'s label is \" + str(train_labels[random_image]) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "<u>1. Declaring pre-processing functions:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(array):\n",
    "    \"\"\"\n",
    "    Converts a numpy array of shape (number_instances, 1) to one-hot encodings\n",
    "    of shape (number_instances, number_labels)\n",
    "    ---\n",
    "    variable <array>: <class 'numpy.ndarray'>\n",
    "    \"\"\"    \n",
    "    # Using np.reshape is necessary so the one-hot encodings are not a nested list.\n",
    "    new_array = np.array(array).reshape(-1)\n",
    "    return np.eye(np.max(array)+1)[new_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Reshaping train and test image/label arrays:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:\n",
      "- Training features array: (60000, 28, 28, 1)\n",
      "- Training labels array: (60000, 1)\n",
      "- Testing features array: (10000, 28, 28, 1)\n",
      "- Testing features array: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Expanding by 1 the dimension of train and test images to indicate that MNIST data are \n",
    "#in greyscale, i.e. 1 channel\n",
    "train_images = np.expand_dims(train_images,axis=3)\n",
    "test_images = np.expand_dims(test_images,axis=3)\n",
    "\n",
    "# Reshaping labels to indicate the dimension of the secondary axis\n",
    "train_labels = np.reshape(train_labels,(train_labels.shape[0],1))\n",
    "test_labels = np.reshape(test_labels,(test_labels.shape[0],1))\n",
    "\n",
    "print(\"Dimensions of:\",\n",
    "      \"- Training features array: \" + str(train_images.shape), \n",
    "      \"- Training labels array: \" + str(train_labels.shape), \n",
    "      \"- Testing features array: \" + str(test_images.shape), \n",
    "      \"- Testing features array: \" + str(test_labels.shape), \n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>3. Normalizing features:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing features. \n",
    "norm_train_images = train_images.astype(np.float32)/np.max(train_images) #i.e. /255\n",
    "norm_test_images = test_images/np.max(test_images) #i.e. /255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>4. Converting train and test labels arrays to one-hot encodings:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_labels = convert_to_one_hot(train_labels)\n",
    "encoded_test_labels = convert_to_one_hot(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of:\n",
      "- Training labels one-hot encoded array:(60000, 10)\n",
      "- Test labels one-hot encoded array:(60000, 10)\n",
      "\n",
      "Image n째49456's one-hot encoding is [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.].\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of:\",\n",
    "      \"- Training labels one-hot encoded array:\" + str(encoded_train_labels.shape),\n",
    "      \"- Test labels one-hot encoded array:\" + str(encoded_test_labels.shape),\n",
    "      \"\\nImage n째\" + str(random_image) + \"'s one-hot encoding is \" + \\\n",
    "      str(encoded_train_labels[random_image]) + \".\",\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Laying out the CNN Model\n",
    "\n",
    "<u>1. Declaring pre-processing functions:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_shape(array):\n",
    "    \"\"\"\n",
    "    Returns the height, width of instance data.\n",
    "    ---\n",
    "    variable <array>: <class 'numpy.ndarray'>\n",
    "    \"\"\"\n",
    "    return array.shape[1], array.shape[2]\n",
    "    \n",
    "def tensorflow_placeholders(instance_height, \n",
    "                            instance_width, \n",
    "                            instance_channels, \n",
    "                            label_numbers):\n",
    "    \"\"\"\n",
    "    Creates tensorflow placeholders for a tensorflow session.\n",
    "    ---\n",
    "    variables <class 'int'>: <instance_height>, <instance_width>, <instance_channel>, <label_numbers>\n",
    "    \"\"\"\n",
    "    placeholder_data = tf.placeholder(tf.float32, shape=(None,\n",
    "                                                         instance_height,\n",
    "                                                         instance_width,\n",
    "                                                         instance_channels))\n",
    "    placeholder_labels = tf.placeholder(tf.float32, shape=(None, label_numbers))\n",
    "    return placeholder_data, placeholder_labels\n",
    "\n",
    "def initialize_parameters(variable_name, filter_shape):\n",
    "    \"\"\"\n",
    "    Initializes weght parameters and returns returns a tensor with shape:\n",
    "    [filter_height, filter_width, in_channels, out_channels].\n",
    "    ---\n",
    "    variable <class 'int'>: <filter_height>, <filter_width>, <channels_in>, <channels_out>\n",
    "    variable <class 'lst'>: <filter_shape> (listing variables: <class 'int'>)\n",
    "    variable <class 'str'>: <variable_name>\n",
    "    \"\"\"\n",
    "    weights = tf.get_variable(variable_name, filter_shape, \n",
    "                              initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>2. Setting up tensorflow session structure:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeds random numbers for tensor parameters\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# Scalar used for setting up tensorflow session.\n",
    "instance_height, instance_width = instance_shape(norm_train_images)\n",
    "instance_channels = 1\n",
    "label_numbers = encoded_train_labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow placeholder for instance data:\n",
      "Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensorflow placeholder for instance labels:\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creating tensorflow placeholders.\n",
    "placeholder_data, placeholder_labels = tensorflow_placeholders(instance_height, \n",
    "                                                               instance_width, \n",
    "                                                               instance_channels, \n",
    "                                                               label_numbers)\n",
    "print(\"Tensorflow placeholder for instance data:\",\n",
    "      placeholder_data,\n",
    "      \"Tensorflow placeholder for instance labels:\",\n",
    "      placeholder_labels\n",
    "      , sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating the weights parameters\n",
    "convolution_filter_shapes = ([1,1,1,16],\n",
    "                             [4,4,16,16],\n",
    "                             [2,2,16,8],\n",
    "                             [2,2,8,8])\n",
    "\n",
    "parameters = {\"W1\":initialize_parameters(\"W1\", convolution_filter_shapes[0]),\n",
    "              \"W2\":initialize_parameters(\"W2\", convolution_filter_shapes[1]),\n",
    "              \"W3\":initialize_parameters(\"W3\", convolution_filter_shapes[2]),\n",
    "              \"W4\":initialize_parameters(\"W4\", convolution_filter_shapes[3])}\n",
    "\n",
    "#Declaring the hyperparameters\n",
    "strides = {\"cnn_layer_1\": [1,1,1,1], \n",
    "           \"cnn_layer_2\": [1,1,1,1], \n",
    "           \"cnn_layer_3\": [1,1,1,1], \n",
    "           \"cnn_layer_4\": [1,1,1,1], \n",
    "           \"max_pool_layer_1\": [1,3,3,1],\n",
    "           \"max_pool_layer_2\": [1,3,3,1],\n",
    "           \"max_pool_layer_3\": [1,3,3,1],\n",
    "           \"max_pool_layer_4\": [1,3,3,1]}\n",
    "\n",
    "kernel_size = {\"max_pool_layer_1\": [1,3,3,1], \n",
    "               \"max_pool_layer_2\": [1,3,3,1], \n",
    "               \"max_pool_layer_3\": [1,3,3,1], \n",
    "               \"max_pool_layer_4\": [1,3,3,1]}\n",
    "\n",
    "padding = {\"cnn_layer_1\": \"SAME\", \n",
    "           \"cnn_layer_2\": \"SAME\", \n",
    "           \"cnn_layer_3\": \"SAME\", \n",
    "           \"cnn_layer_4\": \"SAME\", \n",
    "           \"max_pool_layer_1\": \"SAME\", \n",
    "           \"max_pool_layer_2\": \"SAME\", \n",
    "           \"max_pool_layer_3\": \"SAME\", \n",
    "           \"max_pool_layer_4\": \"SAME\"}\n",
    "\n",
    "output_layer_size = len(np.unique(train_labels))\n",
    "\n",
    "hyperparameters = {\"strides\": strides, \n",
    "                   \"kernel_size\": kernel_size, \n",
    "                   \"padding\": padding, \n",
    "                   \"output_size\": output_layer_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(data, parameters, hyperparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the machine learning model.\n",
    "    ---\n",
    "    variable <class 'numpy.ndarray'>: data\n",
    "    variable <class 'dict'>: parameters, hyperparameters\n",
    "    \"\"\"\n",
    "    #############\n",
    "    ###LAYER 1###\n",
    "    #CONV2D\n",
    "    Z1 = tf.nn.conv2d(data, \n",
    "                      parameters[\"W1\"], \n",
    "                      strides = hyperparameters[\"strides\"][\"cnn_layer_1\"], \n",
    "                      padding = hyperparameters[\"padding\"][\"cnn_layer_1\"])\n",
    "    #RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    #MAXPOOL\n",
    "    P1 = tf.nn.max_pool(A1, \n",
    "                        ksize = kernel_size[\"max_pool_layer_1\"], \n",
    "                        strides = hyperparameters[\"strides\"][\"max_pool_layer_1\"], \n",
    "                        padding = hyperparameters[\"padding\"][\"max_pool_layer_1\"])\n",
    "    #############\n",
    "    ###LAYER 2###\n",
    "    #CONV2D\n",
    "    Z2 = tf.nn.conv2d(P1, \n",
    "                      parameters[\"W1\"], \n",
    "                      strides = hyperparameters[\"strides\"][\"cnn_layer_1\"], \n",
    "                      padding = hyperparameters[\"padding\"][\"cnn_layer_1\"])\n",
    "    #RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    #MAXPOOL\n",
    "    P2 = tf.nn.max_pool(A2, \n",
    "                        ksize = kernel_size[\"max_pool_layer_1\"], \n",
    "                        strides = hyperparameters[\"strides\"][\"max_pool_layer_1\"], \n",
    "                        padding = hyperparameters[\"padding\"][\"max_pool_layer_1\"])\n",
    "    #############\n",
    "    ###LAYER 3###\n",
    "    #CONV2D\n",
    "    Z3 = tf.nn.conv2d(P2, \n",
    "                      parameters[\"W1\"], \n",
    "                      strides = hyperparameters[\"strides\"][\"cnn_layer_1\"], \n",
    "                      padding = hyperparameters[\"padding\"][\"cnn_layer_1\"])\n",
    "    #RELU\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    #MAXPOOL\n",
    "    P3 = tf.nn.max_pool(A3, \n",
    "                        ksize = kernel_size[\"max_pool_layer_1\"], \n",
    "                        strides = hyperparameters[\"strides\"][\"max_pool_layer_1\"], \n",
    "                        padding = hyperparameters[\"padding\"][\"max_pool_layer_1\"])\n",
    "    #############\n",
    "    ###LAYER 4###\n",
    "    #CONV2D\n",
    "    Z4 = tf.nn.conv2d(P3, \n",
    "                      parameters[\"W1\"], \n",
    "                      strides = hyperparameters[\"strides\"][\"cnn_layer_1\"], \n",
    "                      padding = hyperparameters[\"padding\"][\"cnn_layer_1\"])\n",
    "    #RELU\n",
    "    A4 = tf.nn.relu(Z4)\n",
    "    #MAXPOOL\n",
    "    P4 = tf.nn.max_pool(A4, \n",
    "                        ksize = kernel_size[\"max_pool_layer_1\"], \n",
    "                        strides = hyperparameters[\"strides\"][\"max_pool_layer_1\"], \n",
    "                        padding = hyperparameters[\"padding\"][\"max_pool_layer_1\"])\n",
    "    #############\n",
    "    ###LAYER 5###\n",
    "    #FLATTEN\n",
    "    F = tf.contrib.layers.flatten(P4)\n",
    "    #FULLY-CONNECTED\n",
    "    Z5 = tf.contrib.layers.fully_connected(F, \n",
    "                                           hyperparameters[\"output_size\"], \n",
    "                                           activation_fn = None)\n",
    "    return Z5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(data, labels):\n",
    "    \"\"\"\n",
    "    Computes the cost of the model.\n",
    "    ---\n",
    "    variables <class 'numpy.ndarray'>: data, labels\n",
    "    \"\"\"\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = data, \n",
    "                                                                  labels = labels))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"WIP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"WIP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Implementing LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"WIP\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
